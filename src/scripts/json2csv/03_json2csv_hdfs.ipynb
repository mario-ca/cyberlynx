{"cells":[{"cell_type":"markdown","metadata":{},"source":["### Conversión de dataset de tipo de HDFS de JSON a CSV"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":256,"status":"ok","timestamp":1718454796259,"user":{"displayName":"MARIO DANIEL CASTRO ALMENZAR","userId":"03658735314644284318"},"user_tz":-120},"id":"3Qk5bvELep_h"},"outputs":[],"source":["import pandas as pd\n","import re\n","import csv\n","from io import StringIO\n","import json"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1718454797475,"user":{"displayName":"MARIO DANIEL CASTRO ALMENZAR","userId":"03658735314644284318"},"user_tz":-120},"id":"7onawvasesXU"},"outputs":[],"source":["# Corregir posibles errores en la línea\n","def repair_json_line(line):\n","    # Asegurar que todas las claves estén entre comillas dobles\n","    line = re.sub(r'(?<=,|\\{)\\s*([^\"{\\s][^:]*?)\\s*:', r' \"\\1\":', line.replace(\"'\", '\"'))\n","    # Añadir comas necesarias si no es el final del archivo y no termina en coma o cierre\n","    if line.strip() and not line.strip().endswith(('}', ']', ',')):\n","        line += ','\n","    return line"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1718454798673,"user":{"displayName":"MARIO DANIEL CASTRO ALMENZAR","userId":"03658735314644284318"},"user_tz":-120},"id":"zls85PU6nK8P"},"outputs":[],"source":["# Limpiar y cargar un archivo CSV\n","def load_and_clean_json(filename):\n","    try:\n","        with open(filename, 'r') as file:\n","            data = json.load(file)\n","        return pd.DataFrame(data)\n","    except json.JSONDecodeError as e:\n","        print(f\"Error decoding JSON: {e}\")\n","        # Devolver un DataFrame vacío en caso de error\n","        return pd.DataFrame()  \n"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":290,"status":"ok","timestamp":1718454799954,"user":{"displayName":"MARIO DANIEL CASTRO ALMENZAR","userId":"03658735314644284318"},"user_tz":-120},"id":"NkqKVkyTiFzu"},"outputs":[],"source":["# Obtener el contenido de una línea de un fichero\n","def get_line_content(filename, line_number):\n","    try:\n","        with open(filename, 'r') as file:\n","            for current_line, content in enumerate(file, start=1):\n","                if current_line == line_number:\n","                    return content\n","    except Exception as e:\n","        return f\"Error reading line: {str(e)}\""]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":949,"status":"ok","timestamp":1718454802439,"user":{"displayName":"MARIO DANIEL CASTRO ALMENZAR","userId":"03658735314644284318"},"user_tz":-120},"id":"DHCdQucteU2t","outputId":"105efd03-54eb-45b2-a7e4-acbb1ff95e6d"},"outputs":[{"name":"stdout","output_type":"stream","text":["             timestamp                   hostname  \\\n","0  2008-11-09T20:35:18                      block   \n","1  2008-11-09T20:35:18  NameSystem.allocateBlock:   \n","2  2008-11-09T20:35:19                      block   \n","3  2008-11-09T20:35:19                      block   \n","4  2008-11-09T20:35:19                          1   \n","\n","                                             service  \\\n","0                                -160899968791986290   \n","1  /hadoop/mapred/system/job_200811092030_0001/jo...   \n","2                                -160899968791986290   \n","3                                -160899968791986290   \n","4                                                      \n","\n","                                             message  \n","0  src: /10.250.19.102:54106 dest: /10.250.19.102...  \n","1                           blk_-1608999687919862906  \n","2   src: /10.250.10.6:40524 dest: /10.250.10.6:50010  \n","3  src: /10.250.14.224:42420 dest: /10.250.14.224...  \n","4         block blk_-1608999687919862906 terminating  \n"]}],"source":["# Cargar y limpiar el archivo JSON\n","df = load_and_clean_json('0X_nombre_dataset.json')\n","if df is not None and not df.empty:\n","    print(df.head())\n","else:\n","    print(\"Fallo al cargar el archivo JSON.\")"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3127,"status":"ok","timestamp":1718454809570,"user":{"displayName":"MARIO DANIEL CASTRO ALMENZAR","userId":"03658735314644284318"},"user_tz":-120},"id":"vP7nIdmzeYrA","outputId":"e083e274-c6a0-4ca9-cf38-073df92d0fea"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-29-c1d6e9a22372>:3: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n","  df['time'] = pd.to_datetime(df['timestamp'], errors='coerce', infer_datetime_format=True)\n"]},{"name":"stdout","output_type":"stream","text":["                      time  YYYY  MM  DD  hh:mm\n","0      2008-11-09 20:35:18  2008  11  09  20:35\n","1      2008-11-09 20:35:18  2008  11  09  20:35\n","2      2008-11-09 20:35:19  2008  11  09  20:35\n","3      2008-11-09 20:35:19  2008  11  09  20:35\n","4      2008-11-09 20:35:19  2008  11  09  20:35\n","...                    ...   ...  ..  ..    ...\n","276148 2008-11-09 21:11:11  2008  11  09  21:11\n","276149 2008-11-09 21:11:11  2008  11  09  21:11\n","276150 2008-11-09 21:11:11  2008  11  09  21:11\n","276151 2008-11-09 21:11:11  2008  11  09  21:11\n","276152 2008-11-09 21:11:11  2008  11  09  21:11\n","\n","[276153 rows x 5 columns]\n"]}],"source":["# Suponiendo que df ya está cargado con la data del JSON\n","try:\n","    df['time'] = pd.to_datetime(df['timestamp'], errors='coerce', infer_datetime_format=True)\n","    df['YYYY'] = df['time'].dt.year.apply(lambda x: f'{x:4}')\n","    df['MM'] = df['time'].dt.month.apply(lambda x: f'{x:02}')\n","    df['DD'] = df['time'].dt.day.apply(lambda x: f'{x:02}')\n","    df['hh:mm'] = df['time'].dt.strftime('%H:%M')\n","\n","    # Muestra los resultados de la conversión y las nuevas columnas\n","    print(df[['time', 'YYYY', 'MM', 'DD', 'hh:mm']])\n","except Exception as e:\n","    print(f\"Error processing dates: {e}\")"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":16480,"status":"ok","timestamp":1718454830393,"user":{"displayName":"MARIO DANIEL CASTRO ALMENZAR","userId":"03658735314644284318"},"user_tz":-120},"id":"3FLNi-_BegVn"},"outputs":[],"source":["# Funciones para extraer las distintas columnas del campo principal 'message'\n","def extract_ip(message):\n","    match = re.search(r'\\b(?:\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3})\\b', message)\n","    return match.group(0) if match else None\n","\n","df['IP'] = df['message'].apply(extract_ip)\n","\n","def extract_port(message):\n","    common_ports = {\n","        '21': 'FTP', '22': 'SSH', '23': 'Telnet', '25': 'SMTP', '53': 'DNS',\n","        '80': 'HTTP', '110': 'POP3', '143': 'IMAP', '443': 'HTTPS', '587': 'SMTP',\n","        '3306': 'MySQL', '5432': 'PostgreSQL', '8080': 'HTTP-alt'\n","    }\n","    matches = re.findall(r'\\b\\d{2,5}\\b', message)\n","    ports = [port for port in matches if port in common_ports]\n","    return ports[0] if ports else None\n","\n","df['Port'] = df['message'].apply(extract_port)\n","\n","def extract_keyword(message):\n","    keywords = ['error', 'fatal', 'failure', 'exception', 'warning', 'critical', 'denied', 'unreachable', 'timeout', 'failed']\n","    pattern = re.compile('|'.join(keywords), re.IGNORECASE)\n","    match = pattern.search(message)\n","    return match.group(0) if match else None\n","\n","def extract_action(message):\n","    actions = ['restarted', 'stopped', 'started', 'deployed']\n","    pattern = r'\\b(' + '|'.join(actions) + r')\\b'\n","    match = re.search(pattern, message, re.IGNORECASE)\n","    return match.group(0) if match else None\n","\n","df['Action'] = df['message'].apply(extract_action)\n","\n","df['Keyword'] = df['message'].apply(extract_keyword)\n","\n","df['User'] = df['message'].apply(lambda x: re.findall(r'user\\s+(\\w+)', x)[0] if re.findall(r'user\\s+(\\w+)', x) else None)\n","\n","def extract_interface(message):\n","    pattern = r'\\b(eth0|eth[12]|wlan0|lo)\\b'\n","    match = re.search(pattern, message)\n","    return match.group(0) if match else None\n","\n","df['Interface'] = df['message'].apply(extract_interface)\n","\n","\n","df['UID'] = df['message'].apply(lambda x: re.findall(r'uid=(\\d+)', x)[0] if re.findall(r'uid=(\\d+)', x) else None)\n","\n","df['Protocol'] = df['message'].apply(lambda x: re.findall(r'\\b(TCP|UDP)\\b', x, re.IGNORECASE)[0] if re.findall(r'\\b(TCP|UDP)\\b', x, re.IGNORECASE) else None)\n","\n","df['Component'] = df['message'].apply(lambda x: re.findall(r'\\b(RAS)\\b', x)[0] if re.findall(r'\\b(RAS)\\b', x) else None)\n","\n","df['Severity'] = df['message'].apply(lambda x: re.findall(r'\\b(KERNEL|DISCOVERY)\\b', x)[0] if re.findall(r'\\b(KERNEL|DISCOVERY)\\b', x) else None)\n","\n","df['Type'] = df['message'].apply(lambda x: re.findall(r'\\b(INFO|FATAL|SEVERE|WARNING|ERROR)\\b', x, re.IGNORECASE)[0] if re.findall(r'\\b(INFO|FATAL|SEVERE|WARNING|ERROR)\\b', x, re.IGNORECASE) else None)\n","\n","df['Thread ID'] = df['message'].apply(lambda x: re.findall(r'\\bthread\\s+(\\d+)\\b', x, re.IGNORECASE)[0] if re.findall(r'\\bthread\\s+(\\d+)\\b', x, re.IGNORECASE) else None)\n","\n","df['message'] = df['message'].apply(lambda x: x.replace('\\t', ' ').replace('\"', '\"\"'))\n","\n","df = df[['YYYY', 'MM', 'DD', 'hh:mm', 'hostname', 'service', 'User', 'IP', 'Port', 'Keyword', 'Interface', 'UID', 'Action', 'Protocol', 'Component', 'Severity', 'Type', 'Thread ID', 'message']]\n","\n","output = StringIO()\n","df.to_csv(output, sep='\\t', index=False, header=False)\n","output.seek(0)\n","\n","lines = output.readlines()\n","formatted_lines = []\n","\n","# Definición de las columnas del dataset en el orden correcto\n","headers = ['YYYY', 'MM', 'DD', 'hh:mm', 'Hostname', 'Service', 'User', 'IP', 'Port', 'Keyword', 'Interface', 'UID', 'Action', 'Protocol', 'Component', 'Severity', 'Type', 'Thread ID', 'Message']\n","max_widths = [max(max(len(row[i]) for row in (line.split('\\t') for line in lines)), len(header)) for i, header in enumerate(headers)]\n","\n","# Preparación del formato de las columnas\n","header_line = \"\".join(f'{header:<{max_widths[i]}}\\t' for i, header in enumerate(headers))\n","formatted_lines.append(header_line.strip() + '\\n')"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":4601,"status":"ok","timestamp":1718454837638,"user":{"displayName":"MARIO DANIEL CASTRO ALMENZAR","userId":"03658735314644284318"},"user_tz":-120},"id":"i02UpMsqf_ar"},"outputs":[],"source":["# Formateo de las líneas del dataset\n","for line in lines:\n","    row = line.split('\\t')\n","    # Verificación del número de columnas\n","    if len(row) == len(max_widths):\n","        formatted_line = \"\".join(f'{item.strip():<{max_widths[i]}}\\t' for i, item in enumerate(row))\n","        formatted_lines.append(formatted_line.strip() + '\\n')\n","    else:\n","        print(\"Error: Row has incorrect number of columns\", row)"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":270,"status":"ok","timestamp":1718454852356,"user":{"displayName":"MARIO DANIEL CASTRO ALMENZAR","userId":"03658735314644284318"},"user_tz":-120},"id":"0Pm5B0jTeh_E"},"outputs":[],"source":["# Escritura de las líneas formateadas en un archivo CSV\n","with open('0X_nombre_dataset.csv', 'w') as file:\n","    file.writelines(formatted_lines)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNriCDwmE2kpA3YZs9PUmfz","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
